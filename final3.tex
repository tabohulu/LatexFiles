\documentclass[fontsize=12pt]{article}
%\usepackage{xeCJK}
\usepackage{amsfonts}
\usepackage[makeroom]{cancel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{setspace}
\doublespacing
\newcommand{\td}{\cdot\cdot\cdot}
\newcommand{\cd}{\cdot}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
		T\kern-.167em\lower.7ex\hbox{E}\kern-.125emX}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}
%\setCJKmainfont{SimSun}
\title{A Method For Listing All Low-Weight Parity Bit Codewords For RSC Codes} 
\author{Kwame Ackah Bohulu}
\date{\today}
\begin{document}
\maketitle

\newpage
\paragraph{Abstract -}
In this paper, we present a novel low-complexity method for listing all message inputs which produce codewords with low-weight parity bit sequences for a specific Recursive Systematic Convolutional (RSC) Code.
This method is implemented by  treating the RSC code as closed finite-state machine and determining all paths through the trellis that begin and end at state 0 for a given trellis length. Using this method, we determine all messages which produce codewords with parity-bit sequence weight $W_p$ for message input with length $K$. We calculate the upper-bound for the Probability of Bit Error  of the given RSC code using the partial distance spectrum obtained using the proposed method. Simulation results reveal that this new bound is very close to existing  bounding techniques.

\section{Introduction}

A Convolutional Code (CC) is generated by passing a message input through a linear finite-state shift register. The structure of this code is such that it is best described using a trellis. This structure makes it possible to employ soft decision decoding algorithms, the most popular of these algorithms being the Viterbi algorithm. CC are used extensively in mobile communication and space communication application as a major component in concatenated code.  Depending on the configuration of the shift register being used to generate the code, a CC can either be \textit{recursive} or \textit{nonrecursive}. In the case of the recursive CC, a feedback shift register is used to generate the code. Furthermore if the the message input appears in the CC, it is known as \textit{systematic}. Recursive Sytematic Convolutional Codes(RSCC's) are used as component codes for Turbo codes, which are one of the few error correcting codes with performance very close to the Shannon limit [1].

Low weight codeword may be produced when the parity bit sequence has a very low weight. Amongst all such codewords, the one with the lowest weight determines the free distance $d_{\text{free}}$ of the code. 
$d_{\text{free}}$  of a RSCC is a very important factor and determines its error-correction performance [4].  This can be obtained from the distance spectrum of the RSCC which requires the calculation of the transfer function. %, where 
 As the number of states present in the RSCC increases so does the complexity involved in calculating the transfer function. Furthermore, the transfer function only provides information about the number of codewords of weight $d$ generated by message input of weight $i$. There is no extra information with regards to the structure of the message input which generates which low-weight parity bit sequences and possibly low-weight codewords.

In this research paper, we present a novel method which can be used to easily determine which message inputs of length $K$ will result in parity bit sequences which has a specific weight after it has been encoded with an RSC encoder. This method does not require the calculation of the transfer function of the RSCC. Using this method we calculate the theoretical upper bound for the given RSC code using the partial distance spectrum obtained. 
%The rest of the research paper is organised as follows. In Section \ref{sec2}, we give a brief review of RSC codes. In section \ref{sec7}, we describe how the distance spectrum of a RSCC is obtained using the transfer function, followed by the presentation of our novel method in Section \ref{sec3}. In section \ref{sec4}, we derive the upper bound for a given RSC code based on our novel method. Simulation results are presented in Section \ref{sec5} and we conclude our research paper in Section \ref{sec6}

\section{Recursive Systematic Convolutional Codes:Review}
\label{sec2}

An  $(m,k)$ RSCC is a convolutional code generated by using feedback shift registers which has its input bits as part of the codeword. At each time instant it receives an input of $k$ bits and outputs $m$ bits. The output bits are determined by the generator function, which may be written in $D$ notation as  $[1 ~\frac{F(D)}{H(D)}]$ or simply as $[\frac{F(D)}{H(D)}]$ where $F(D)$ and $H(D)$ represent the feedfoward and feedback connections of the component encoder.

It should be noted that the prescence of the feedback loop means that the code produced will have an infinite-length impulse response. A parameter which arises as a result of this infinite impulse response is know as the cycle length which we will represent by $\tau$. The cycle length [5] is defined as the output cycle of an RSC encoder when the input is $[1 0 0 0 .....]$. This output which is represented by $\textbf{t}$ is with respect to the parity check bits only and is the impulse response of the RSCC. The cycle is represented by $\textbf{p}$ and is unique for each RSCC. 

%To improve the ability of a decoder, it is requred that the start state and the end state be the same. The process of doing this is know as \textit{terminating} the code. Popular methods include tail-biting and terminating with extra bits. In all our simulations both methods are employed.

For the decoding of RSCC's, the Viterbi decoder is used. The idea is to go through the trellis of the RSCC and determine the most probable path through the trellis which corresponds to the transmitted message input.

The distance spectrum of code gives information about codewords and the number of such codewords present in the code. For the RSCC, this can be obtained from its transfer function.  

\begin{figure}[h]
\centering
		\includegraphics[width=0.45\textwidth]{RSCExample3.pdf}
		\caption{$[\frac{1+D^2}{1+D+D^2}]$  RSC Encoder}
		\label{fig1}
		\end{figure}
		
A RSC encoder is shown in Figure \ref{fig1}. Its generator function is given by $[\frac{1+D^2}{1+D+D^2}]$ which may be written as $(5,7)$ in octal form where $5 ~ \text{and} ~ 7$ correspond to the numerator and denomenator of the generator function respectively. 
 For the $(5,7)$ RSC code, the output is of the form $\textbf{t}=[1 1 1 0 1 1 0 1 1 0 ...]$ which gives us a cycle $\textbf{p}$ of $[1 1 0]$ and a cycle length $\tau =3$. Also $k=1$ and $m=2$
The knowledge of $\textbf{p}$ and $\tau$ will be used in deriving the method for determing which input messages generate low-weight parity bits. 


\section{Transfer Function of RSCC}
\label{sec7}
The transfer function of a CC provides information about the distance spectrum of the code. Based on the method described in [3], we outline the process involved in deriving the transfer function of the $(5,7)$ RSCC. 

\begin{figure}[h]
\centering
		\includegraphics[width=0.75\textwidth]{tf.png}
		\caption{State Diagram of the $(5,7)$ RSCC }
		\label{fig4}
		\end{figure}
First, the state diagram of the $(5,7)$ RSCC is redrawn as shown in Figure \ref{fig4}. The zero state is split into two and the transition from the zero state to itself is ommited. On each edge, the variables $D^d$ and $N^i$ are used to represent the output weight $d$ and input weight $w$ of the path respectively. We treat each edge label as a transfer block and we employ the following rules for graph simplification. Assume two labels $H$ and $G$ 

\begin{enumerate}
\item If the states are connected in series, $HG$

\item If the states are connected in parallel, $H+G$

\item If the states are in a feedback configuration, $\frac{H}{1-HG}$
\end{enumerate}

The process for deriving the transfer function is shown in Example {\ref{ex3}}

\begin{example} Define all edge labels\\
\label{ex3}
 edge $ a\triangleq 0 0 \rightarrow 1 0$,  edge $b \triangleq 1 0 \rightarrow 0 1$\\
 edge $ c \triangleq 0 1 \rightarrow 0 0$, edge $d \triangleq 0 1 \rightarrow 1 0$\\
 edge $ e \triangleq 1 0 \rightarrow 1 1$, edge $f \triangleq 1 1 \rightarrow 1 1$\\
 edge $ g \triangleq 1 1 \rightarrow 1 0$

\begin{enumerate}
\item Simplify edge $g$ with feedback configuration

$$ \frac{1}{1-DN}$$

\item Merge edges $e,f,g$ into edge $h$ with series configuration

$$\text{edge}~h = D\times \frac{1}{1-DN}\times D=\frac{D^2}{1-DN}$$

\item Merge edges $h,b$ into edge $j$ with parallel configuration

$$\text{edge}~j = DN+ \frac{D^2}{1-DN}= \frac{DN+D^2N^2+D^2}{1-DN}$$

\item Merge  edges $j,d$ into edge $k$ with feedback configuration
\begin{equation*}
\begin{split}
 \text{edge}~k&= \frac{\frac{DN+D^2N^2+D^2}{1-DN}}{1-(\frac{DN+D^2N^2+D^2}{1-DN})}\\
 &=\frac{D(N-DN^2+D)}{1-2DN+D^2N^2-D^2}
\end{split}
\end{equation*}

\item Calculate transfer function by merging edges $k,a,c$ with series configuration

\begin{equation*}
\begin{split}
T(D,N)&=D^2N \times \frac{D(N-DN^2+D)}{1-2DN+D^2N^2-D^2}\times D^2N \\
&=\frac{D^5N^2(N-DN^2+D)}{1-2DN+D^2N^2-D^2}\\
&=D^5N^3+D^6(N^4+N^2)+D^7(N^5+3N^3)+\\
&D^8(N^6+6N^4+N^2)+D^9(N^7+10N^5+5N^3)+...
\end{split}
\end{equation*}
\end{enumerate}
\end{example}

From the example, it is clear that the complexity involved in deriving the transfer function increases as the number of states of the RSCC increases. Also to obtain the distance spectrum requires an extra division operation. Furthermore, with this method, it is impossible to get any extra detail regarding the structure of the message bits which correspond to a codeword of a particular weight. We present a method which has less complexity and provides more information with regards to the distance spectrum in the next section.

\section{Method for Determining Parity Check Bit Weights}
\label{sec3}
In this section, we wish to present a method for determining the input messages which generate low weight parity bits. 




%$b(x) = b_0x^0+b_1x_1+...+b_{N-1}x_{N-1}$ 
Let $\textbf{b} =[b_0 b_1 ... b_{K-1}]$ be a message input of length $K$ . We assume that $\textbf{b}$ is encoded using the $(5,7)$ RSC encoder to produce a codeword $\textbf{v}=[v_0 v_1 v_2 v_3 v_4 v_5 ... v_{M-1}]$, where $M=\frac{mK}{k}$. This codeword is formed from multiplexing  systematic bits and the parity bits. The systematic bits are made up of the message input itself and are found in the even numbered part of the codeword, whiles the parity bits are determined by the past and present input bits fed into the encoder. 
We represent the parity bits by 
$\textbf{c}=[c_0 c_1 c_2 ... c_{K-1}] \equiv [v_1 v_3 v_5 ... v_{M-1}]$

As mentioned earlier,our interest is to determine if a given message input $\textbf{b}$ will produce low-weight parity bit sequence. With the knowlege of the impulse response of the  RSC encoder and a little algebra, it is possible to determine what the parity bits will be and by extension, the weight of the parity bits. 
 
 We write $\textbf{b}$ and $\textbf{c}$ in polynomial form as $b(x)$ and $c(x)$. We also represent the impulse in polynomial form as $t(x)$. In the polynomial representation, only ``1'' bits are of interest. Also all calculations are carried out using modulo 2 arithmetic.
$c(x)$ is calculated using (\ref{eq3})
 \begin{equation}
 \begin{split}
 c(x)&=\hat{t}(x)b(x)\\
 \end{split}
 \label{eq3}
 \end{equation}
 where $\hat{t}(x)$ is $t(x)$ written ignoring all powers greater than $x^{\tau}$
 
 We focus on the portion of $c(x)$ with powers greater than $x^{(n)}$ , where $n$ is the highest power of b(x). We refer to it as the stational state and represent it in polynomial form as $c_p(x)$.  We may write $c_p(x)$ using equation 

 \begin{equation}
 c_p(x)  \equiv b(x)p(x) ~\mod{ 1+ x^{\tau}}\\
 \label{eq1}
 \end{equation}
where $p(x)$ is the cycle $\textbf{p}$ of the  RSC code in polynomial form.
 
 In the case where $c_p(x) = 0$, $c(x)$ will have a low weight.  We may write $b(x)$ as 
 $$b(x) \equiv  0 ~\mod{ g(x)} $$ which means it is possible to factorize $b(x)$ as 
 %$b(x) \equiv  0_{\tau}(x) ~\mod{ g(x)} $ 
 \begin{equation}
 b(x) =g(x)a(x)
 \label{eq2}
 \end{equation}
 where $a(x)$ is the quotient obtained after dividing $c_p(x)$ by $1+ x^{\tau}$
 
 Given $b(x)$ and $a(x)$, it is possible to calculate $g(x)$ via polynomial division.
 
 Fixing (\ref{eq2}) into (\ref{eq3}) we have 
 
 \begin{equation}
 \begin{split}
 c(x)&=\hat{t}(x)b(x)\\
 &=\hat{t}(x)g(x)a(x)\\
 & = h(x)a(x)
 \end{split}
 \label{eq4}
 \end{equation}
 where  $h(x)=\hat{i}(x)g(x)$ 
 
 The process is explained further in Example  \ref{ex1}  and Example  \ref{ex1} for $\textbf{b}^{(0)}=[ 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]$ and  $\textbf{b}^{(1)}=[ 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ]$ for the $(5,7)$ RSC encoder. The impulse response $t(x)=1+x+x^2+x^4+x^5+x^7+x^8+....~,p(x)=1+x ~ \text{and} ~ \hat{t}(x)=1+x+x^2$
 
  %In the case of the $(5,7)$ RSC code $\hat{i(x)}=1+x+x^2$ and therefore $h(x)=(1+x+ x^{2})(1+x+ x^{2}) = 1+x^2+ x^4 =1+x^2$ since everything from$ x^4$ is zero when $b(x) \equiv  0_{\tau}(x) ~\mod{ 1+x+ x^{2}} $
\begin{example}
\label{ex1}
$\textbf{b}^{(0)}=[ 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0],~b^{(0)}(x)=x^4+x^5+x^6$

\begin{enumerate}
\item Determine if $c_p^{(0)}(x) =0$

\begin{equation*}
\begin{split}
c_p^{(0)}(x)& \equiv b^{(0)}(x)p(x) \mod{1+x^{\tau}}\\
& \equiv (x^4+x^5+x^6)(1+x)  \mod{1+x^{3}}\\
&\equiv x^4+x^7  \mod{1+x^{3}} =0 ~\text{with remainder }~ a(x) =x^4
\end{split}
\end{equation*}

\item Find $g(x)$
 
 \begin{equation*}
 \begin{split}
 b^{(0)}(x)&=g(x)a(x) \\
 g(x) &=\frac{b^{(0)}(x)}{a(x)}\\
 &=\frac{x^4+x^5+x^6}{x^4}\\
 &=1+x+x^2
 \end{split}
 \end{equation*}
 
 \item Find $c^{(0)}(x)$
 \begin{equation*}
 \begin{split}
 c^{(0)}(x)&=\hat{i}(x)g(x)a(x) \\
 &=(1+x+x^2)^2(x^4)\\
 &=x^4+x^6 ~\text{and}~ h(x)=1+x^2 
 \end{split}
 \end{equation*}
 
\end{enumerate}
\end{example}

\begin{example}
\label{ex2}
$\textbf{b}^{(1)}=[ 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ],~ b(x)=1+x^2$

\begin{enumerate}
\item Determine if $c_p^{(1)}(x) =0$

\begin{equation*}
\begin{split}
c_p^{(0)}(x)& \equiv b^{(1)}(x)p(x) \mod{1+x^{\tau}}\\
& \equiv (1+x^2)(1+x)  \mod{1+x^{3}}\\
&\equiv 1+x+x^2+x^3  \mod{1+x^{3}}\\ &=x+x^2 \neq 0
\end{split}
\end{equation*}
\end{enumerate}
\end{example}
 
 With this knowledge, it is possible to find all message inputs which produce low-weight parity bit sequences and by extension all codewords  with low-weight parity bits. Applying this method directly requires testing all message inputs of length $K$ which is time-consuming and very inefficeint. A better method will be to find all values of $a(x)$ which produce $c(x)$, where $c(x)$ has a low parity weight. This can be acheived using the finite state configuration shown in Figure \ref{fig2}. The state table is shown in Table \ref{tab3}. 
 
\begin{figure}[h]
\centering
		\includegraphics[width=0.45\textwidth]{fsm.png}
		\caption{Finite State Machine Configuration}
		\label{fig2}
		\end{figure}
		
		
		\begin{table*}[h!]
 
 \caption{codewords with parity bit sequence weight $w_H(\textbf{c})=4$}
\centering
 \begin{tabular}{c c c c} 
 \hline
 $w_H(\textbf{b})$ & $a(x)$ & $b(x)$ & $c(x)$ \\ [0.5ex] 
 \hline\hline
 2 & 1+x & $1+x^3$ & $1+x+x^2+x^4$\\ 
 \hline 
  & $1+x+x^2$& $1+x^2+x^4$& $1+x+x^3+x^4$ \\
   3 & $1+x+x^3$& $1+x^4+x^5$ & $1+x+x^2+x^5$ \\
  & $1+x^2+x^3$ & $1+x+x^5$ & $1+x^3+x^4+x^5$ \\
  \hline 
  & $1+x+x^2+x^3 $ & $1+x^2+x^3+x^5$ & $1+x+x^4+x^5$ \\
  & $1+x+x^2+x^4 $ & $1+x^2+x^5+x^6$ & $1+x+x^3+x^6$ \\
 4 & $1+x+x^3+x^5 $ & $1+x^4+x^6+x^7$ & $1+x+x^2+x^7$\\ 
  & $1+x^2+x^3+x^4 $ & $1+x+x^4+x^6$ & $1+x^{3}+x^5+x^6$ \\ 
  & $1+x^2+x^3+x^5 $ & $1+x+x^6+x^7$ & $1+x^{3}+x^4+x^7$ \\  
  & $1+x^2+x^4+x^5 $ & $1+x+x^3+x^7$ & $1+x^5+x^6+x^7$ \\ 
 [1ex]
 \hline
 \end{tabular}
 \label{tab2}
\end{table*}
		The trellis length is set to $K$ and initial state is set to all-zero and the initial input into finite-state machine are set to $1$.  We trace all paths throught the trellis which begin and end at the all-zero state at a stage N of the trellis. $a(x)$ corresponds to the inputs which produce such paths and $b(x)$ corresponds to outputs produced by such paths. Once all valid paths are found we can calculate $g(x)$ using (\ref{eq4}) . Finally, we can find all corresponding values of $b(x)$ using (\ref{eq3}).
 
 For $K=16$ we find all $b(x) ~\text{and}~ c(x)$ for which $w_H(\textbf{c})=2 ~\text{and} ~ w_H(\textbf{c})=4$. The results are shown in Table \ref{tab1} and \ref{tab2} respectively . For $w_H(\textbf{c})=4$, only the first 10 results are shown.  
 
  \begin{table*}[h]
 
 \caption{codewords with parity bit sequence weight $w_H(\textbf{c})=2$}
\centering
 \begin{tabular}{c c c c} 
 \hline
 $w_H(\textbf{b})$ & $a(x)$ & $b(x)$ & $c(x)$ \\ [0.5ex] 
 \hline\hline
 3 & 1 & $1+x+x^2$ & $1+x^2$\\ 
 4 & $1+x^2$ & $1+x+x^3+x^4$ & $1+x^4$ \\
 5 & $1+x^2+x^4$& $1+x+x^3+x^5+x^6$ & $1+x^6$ \\
 6 & $1+x^2+x^4+x^6$& $1+x+x^3+x^5+x^7+x^8$& $1+x^8$ \\
 7 & $1+x^2+x^4+x^6 +x^8$ & $1+x+x^3+x^5+x^7+x^9+x^{10}$ & $1+x^{10}$ \\
 8 & $1+x^2+x^4+x^6 +x^8 +x^{10}$ & $1+x+x^3+x^5+x^7+x^9+x^{11}+x^{12}$ & $1+x^{12}$\\ 
 9 & $1+x^2+x^4+x^6 +x^8+x^{10}+x^{12}$ & $1+x+x^3+x^5+x^7+x^9+x^{11}+x^{13}+x^{14}$ & $1+x^{14}$ \\ [1ex] 
 \hline
 \end{tabular}
 \label{tab1}
\end{table*}
 
   \begin{table}[h!]
 
 \caption{State Table for Finite State Machine in Fig. \ref{fig2}}
\centering
 \begin{tabular}{c c c c} 
 \hline
 $a(x)$ & S & $S'$ & $c(x)$ \\ [0.5ex] 
 \hline\hline
 0 & $0 0 $& $0 0$ & $0$\\ 
  1& $0 0$ & $1 0$ & $1$ \\
  0 & $0 1$& $0 0$ & $1$ \\
  1& $0 1$& $1 0$& $0$ \\
  0& $1 0$ & $0 1$ & $0$ \\
 1 & $1 0 $ & $1 1$ & $1$\\ 
 0 & $1 1$ & $0 1$ & $1$ \\ 
 1 & $1 1$ & $1 1$ & $0$ \\ [1ex] 
 \hline
 \end{tabular}
 \label{tab3}
\end{table}
 
  For each stage in the trellis, the number of paths through the trellis is squared. To reduce the number of calculations per stage, we calculate the weight of the path and get rid of all paths that have an output weight greater than a target weight $w_H(\textbf{c})$

\section{Upper Bound for RSC codes}
\label{sec4}
After a message input \textbf{b} is encoded, it is modulated using an appropriate modulation scheme and transmitted to the receiver over a channel. If the channel is AWGN, noise is added to the signal and the signal at the receiver is $\textbf{r}=[r_0,r_1,r_{2N-1}]$. The receiver demodulates the signal and uses appropriate decoding and detection schemes to produce an estimate of \textbf{b}, $\hat{ \textbf{b} }$. If a wrong decision is made, we say that an error has occurred. To measure how efficient a code is at correcting errors the Bit Error Rate (BER) is used. In most cases, the BER for a code not easily determined and bounds are calculated to give an idea as to how efficient the code is at correcting errors. There are a number of equations used to calculate the upper bound for the BER of a CC and these equations also apply to RSCC. For the case where the code is BPSK modulated and soft Viterbi decoding algorithm is used, the probability of bit error $P_b$ can be calculated using the equation below [3].

\begin{equation}
P_b \leq \frac{1}{k} \sum_{d=d_{\text{free}}}^{\infty} w(d) Q\Bigg( \sqrt{\frac{2dE_c}{N_0}}\Bigg)
\label{eq5}
\end{equation}
where $w(d)=\sum_{i=1}^{\infty} i~ a(d,i)$, $a(d,i)$ is the number of codewords of weight $d$ generated by a message input with weight $i$,  $E_c/N_0$ is the Signal to Noise ratio for the transmitted codeword and $d_{\text{free}}$ is the free distance of the code. This equation require the knowledge of the distance spectrum of the RSCC and as N increases so does the number of computations required to find $w(d)$. For this reason, calculation of $w(d)$ is limited to the first few terms of the distance spectrum. 

Using the method described in the previous section, it is possible to obtain a partial distance spectrum and this partial distance spectrum can be used with (\ref{eq5}) to calculate the upper bound of the RSCC. 

We obtain the partial distance spectrum for all input messages $b(x)$ of length $N=64$ which produce low-weight parity bits
$c(x)$ where $w_H(\textbf{c})=2 ~\text{and} ~ w_H(\textbf{c})=4$. We then use those terms to calculate the probability of bit error using (\ref{eq5}). 

Using the transfer function method, we obtain the distance spectrum up to the first 16 elements and  find the upper bound using (\ref{eq5}).
We then compare both upper bound to the simulation results obtained for the $(5,7)$ RSC encoder.

\section{Simulation Results}
\label{sec5}

\begin{figure}[h]
\centering
		\includegraphics[width=0.55\textwidth]{paperg2.png}
		\caption{Simulation and Upper Bounds for $(5,7)$ RSCC}
		\label{fig3}
		\end{figure}
		
		The simulation results as well as the upper bounds calculated using (\ref{eq5}) and are shown in Figure \ref{fig3}. 
		
		The old bound is calculated by fixing  the distance spectrum derived in Section \ref{sec7} into  (\ref{eq5}) whiles the new bound is calculated using the distance spectrum derived in Section \ref{sec3} and fixing it into (\ref{eq5}). For the simulation, $N=64$ and the soft-Viterbi algorithm is used. Also we use a tail-biting trellis structure. As can be seen from Figure \ref{fig3} the new bound is very close to that of the old bound, especially for $E_b/N_0$ values from $4$ onwards. 

\section{Conclusion}
\label{sec6}
In this research paper, we presented a method for listing all message inputs which produce codewords with low-weight parity bit sequences for a for a given $(m,k)$ RSCC. Compared to the Transfer function method,it has low complexity and provides more information about distance spectrum of the RSCC. Using a specially configured finite state machine, we were able to obtain a partial distance spectrum which we use to calculate an upper bound for the RSCC. Through simulation, we are able to confirm that the new bound is extremely close to existing ones. 




\begin{thebibliography}{99}
\bibitem{ref1}  C. Berrou, A. Glavieux and P. Thitimajshima, 
''Near Shannon limit error-correcting coding and
decoding: Turbo codes'', Proc. Intern. Conf. Communications (ICC), Geneva, 
Switzerland, pp. 1064-
1070, May 1993.
\bibitem{ref2} John G. Proakis, Masoud Salehi. ``Digital Communications'', 
Fifth Edition,Chapter 8, McGraw-Hill.
\bibitem{ref3} Todd K. Moon. ``Error Correcting Codes'',Chapter 12, John Wiley \& Sons.
\bibitem{ref4}Alain Glavieux, ``Channel Coding in Communication Networks'',\\ Chapter 3, John Wiley \& Son. 

\bibitem{ref5} Jing Sun, Oscar Y. Takeshita ''Interleavers for Turbo Codes Using 
Permutation Polynomials over Integer Rings'', IEEE Trans. Inform. Theory, vol. 51, 
pp. 101 - 119  Jan. 2005.

\end{thebibliography}
\end{document}